
---
title: "Lab7"
author: "Javier Mombiela, Jose Hernandez, Pablo Gonzalez"
date: "2023-03-10"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(dplyr)
library(nortest)
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(fastDummies)
library(profvis)
library(mlr)
library(e1071)
library(caret)
```

# Lab 7 Modelo de maquinas Vectorial de Soporte
## 1 Division de variables en datos numericos
### 1.1 Transformacion de la data

Al momento de analizar los datos se pudieron encontrar que muchos de los datos estan en diferentes escalas y tambien que varias columnas cuentan con datos faltantes, ademas se puede concluir por hojas anteriores que ninguno de los datos estas normalziados.
```{r}
datos <-read.csv("train.csv")
datos_numericos <- datos %>%
  select_if(is.numeric)
cualitativas <- datos %>%
  select_if(.predicate = function(x) !is.numeric(x))
datos <- datos %>% mutate_at(colnames(cualitativas), function(x) as.factor(x))
datos_numericos <-datos_numericos[complete.cases(datos_numericos),]
```

```{r}
datos_numericos <-scale(na.omit(datos_numericos))
```
## 2. Creacion de la variable de clasificacion de precios
```{r}
datos_numericos <-data.frame(datos_numericos)
q1 <- quantile(datos_numericos$SalePrice,0.33)
q2 <- quantile(datos_numericos$SalePrice,0.5)
q3 <-quantile(datos_numericos$SalePrice,0.7)
datos_numericos$clasificacion <- sapply(datos_numericos$SalePrice, function(x) ifelse(x <= q1, "Economicas", ifelse(x >= q2 && x <= q3, "Intermedias", "Caras")))
datos_numericos$clasificacion <-factor(datos_numericos$clasificacion)
```
## 3. Cojuntis de train y test
```{r}
porcentaje <- 0.7
set.seed(123)
datos_numericos <-select(datos_numericos, -Id)
corte <- sample(nrow(datos_numericos), nrow(datos_numericos) * porcentaje)
train <- datos_numericos[corte, ]
test <- datos_numericos[-corte, ]
```
## 4. Generar mas de dos modelos de SVM con diferentes kernels y distintos valores en los parametros c y en d
```{r}
modeloSVM_1<-svm(clasificacion~., data=train, cost=2^-5, kernel="linear")
modeloSVM_2<-svm(clasificacion~., data=train, cost=0.5, kernel="linear")
modeloSVM_3<-svm(clasificacion~., data=train, gamma=2^-5, kernel="radial")

```
## 5. Generar las diferentes predicciones de los modelos.
### 5.1 Prediccion primer modelo
```{r}
prediccion1<-predict(modeloSVM_1,newdata=test)
```
### 5.2 Prediccion segundo modelo
```{r}
prediccion2<-predict(modeloSVM_2,newdata=test)
```
### 5.3 Prediccion tercer modelo
```{r}
prediccion3<-predict(modeloSVM_3,newdata=test)
```
## 6. Matrices de confusion de cada modelo

### 6.1 Matriz de confusion primer modelo
```{r}
confusionMatrix(test$clasificacion,prediccion1)
```
### 6.2 Matriz de confusion segundo modelo
```{r}
confusionMatrix(test$clasificacion,prediccion2)
```
### 6.3 Matriz de confusion tecer modelo
```{r}
confusionMatrix(test$clasificacion,prediccion3)
```
## 7. Analisis de sobreajustamiento
### 7.1 Analisis primer modelo
```{r}
    datos.task = makeClassifTask(data = train, target = "clasificacion")
    rin2 = makeResampleDesc(method = "CV", iters = 10, predict = "both")
    lrn = makeLearner("classif.svm", kernel = "linear", cost = 2^-5, type = "C-classification")
    lc2 = generateLearningCurveData(learners = lrn, task = datos.task,
                                    percs = seq(0.1, 1, by = 0.1),
                                    measures = list(ber, setAggregation(ber, train.mean)), resampling = rin2,
                                    show.info = FALSE)
    plotLearningCurve(lc2, facet = "learner")
```
Al momento de realizar la grafica se puede visualizar que la curva de training presenta una tendencia al decenso a pesar de la cantidad de datos que existe, por lo que se puede concluir que este modelo sufre de overfitting. Una de las posibles soluciones que se puede dar es reducir la C para que el modelo acpete mayor cantidad de datos y pueda trabajar mejor.

### 7.2 Analisis segundo modelo
```{r}
    datos.task = makeClassifTask(data = train, target = "clasificacion")
    rin2 = makeResampleDesc(method = "CV", iters = 10, predict = "both")
    lrn = makeLearner("classif.svm", kernel = "linear", cost = 0.5, type = "C-classification")
    lc2 = generateLearningCurveData(learners = lrn, task = datos.task,
                                    percs = seq(0.1, 1, by = 0.1),
                                    measures = list(ber, setAggregation(ber, train.mean)), resampling = rin2,
                                    show.info = FALSE)
    plotLearningCurve(lc2, facet = "learner")
```
Al momento de realizar la grafica se puede visualizar que la curva de training y la de test convergen hacia un mismo punto por lo que se puede conlcluir que este modelo no sufre de overfitting ni underfitting.

```{r warning=FALSE, message=FALSE}
    datos.task = makeClassifTask(data = train, target = "clasificacion")
    rin2 = makeResampleDesc(method = "CV", iters = 10, predict = "both")
    lrn = makeLearner("classif.svm", kernel = "radial", cost = 1, gamma = 2^-5, type = "C-classification")
    lc2 = generateLearningCurveData(learners = lrn, task = datos.task,
                                    percs = seq(0.1, 1, by = 0.1),
                                    measures = list(ber, setAggregation(ber, train.mean)), resampling = rin2,
                                    show.info = FALSE)
    plotLearningCurve(lc2, facet = "learner")
```
Al momento de realizar la grafica se puede mencionar que el modelo sufre de overtfitting esto debido a que primero la curva de training sigue una pequena tendencia a una linea recta y se puede mencionar que  esta y la curva de test estan muy alejadas.

## 8. Comparaciones de algoritmos
Se puede mencionar que el segundo modelo es el único modelo que no presentó overfitting por o cual esto es un gran punto a tomar en cuenta para saber cual es el mejor modelo, en el caso de la precisión se puede mencionar que el mejor modelo fue el modelo 3 el cual obtuvo un accuracy del 0.73 mientras que el peor modelo fue el modelo 2 el cual obtuvo un accuracy de 0.64 lo cual no es tan malo porque acierta más de lo que erra, por lo cual se seleccionará el modelo 2 como el de preferencia.

## 9. Comparar la eficiencia del mejor modelo SVM con los resultados obtenidos en los algoritmos de hojas anteriores
Se puede mencionar que en comparación con los modelos de Hojas anteriores el que sigue resaltando es el modelo de árboles de decisión el cual obtuvo un accuracy de 1 por lo cual se puede concluir que no se equivocó en cambio el modelo de SVM tiene un accuracy de 0.64 por lo cual se va altamente superado y en comparación de los otros modelos como el de random forest y el de naibe_bayes también se ve superado ya que el modelo de random forest obtuvo un 0.96 de accuracy y el modelo de naive bayes de 0.76.


## 10. Generar un modelo de regresion
### 10.1 Modelo de Regresion lineal Simple
```{r}
Modelo_lineal_simple <-lm(SalePrice~OverallQual,data = train)
```
### Resumen del modelo
```{r}
summary(Modelo_lineal_simple)
```
### RMSE
```{r}
PrediccionSimple <-predict(Modelo_lineal_simple,newdata = test)
RMSE(PrediccionSimple,test$SalePrice)
```
### 10.2 Modelo de Regresion Multivariable
```{r}
Modelo_multiV <- lm(train$SalePrice~., data = train)
```
### Resumen del modelo
```{r}
summary(Modelo_multiV)
```
### RMSE
```{r}
PrediccionMulti <- predict(Modelo_multiV,newdata = test)
RMSE(PrediccionMulti,test$SalePrice)
```
## 11. Comparación de Resultados
Se puede mencionar que el modelo de regresión múltiple es el mejor modelo esto debido a que presentó un r^2 de 0.81 mientras que el modelo de regresión generado en hojas anteriores presentó un r^2 de 0.62 y también se puede mencionar que el modelo multivariable presenta un menor RMSE a comparación del primer modelo por lo que esto nos quiere decir que este modelo se ajusta mejor a los datos de entrada y se concluye que el modelo de regresión múltiple es mejor.




